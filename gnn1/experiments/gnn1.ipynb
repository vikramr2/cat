{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d608997-eeff-4c7e-b205-da7450bb4ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import json\n",
    "import csv\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path.cwd().parent.parent.parent.parent\n",
    "DATA_DIR = BASE_DIR / \"oc_mini\"\n",
    "\n",
    "# Add gnn package to path (parent directory)\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sxv7w87yxor",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "You can easily swap the transformer model and data source by modifying these variables below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25yowmg3we3",
   "metadata": {},
   "source": [
    "# GNN Baseline 1: Induced Subgraph with Frozen Transformer\n",
    "\n",
    "**Experiment Goal**: Demonstrate that when a GNN is trained on an induced subgraph of training nodes (with frozen transformer), test nodes with no edges degrade to transformer-only performance.\n",
    "\n",
    "**Setup**:\n",
    "- 90% train nodes, 10% test nodes\n",
    "- Graph contains ONLY edges between training nodes\n",
    "- Transformer (SciBERT) is frozen\n",
    "- Only GNN layers are trainable\n",
    "- Input: Title + Abstract concatenated\n",
    "\n",
    "**Expected Result**: Test nodes will have identical embeddings from transformer-only vs GNN, since they have no graph connectivity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfc18cd-cb4e-44ca-ac45-95ec3dbf24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GNN modules\n",
    "from model import TransformerGNN\n",
    "from graph_utils import (\n",
    "    create_induced_subgraph,\n",
    "    analyze_graph_statistics,\n",
    "    get_node_texts\n",
    ")\n",
    "from split_utils import create_node_based_split\n",
    "\n",
    "# Data paths\n",
    "edgelist_path = DATA_DIR / \"network\" / \"oc_mini_edgelist.csv\"\n",
    "metadata_path = DATA_DIR / \"metadata\" / \"oc_mini_node_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8f37c2-ce7b-48ae-babd-21b6f06976c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded: 14442 entries\n",
      "\n",
      "Train nodes: 12998 (90.0%)\n",
      "Test nodes: 1444 (10.0%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>10.1101/2021.05.10.443415</td>\n",
       "      <td>Improved protein contact prediction using dime...</td>\n",
       "      <td>AbstractDeep residual learning has shown great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163</td>\n",
       "      <td>10.1101/2021.05.07.443114</td>\n",
       "      <td>Following the Trail of One Million Genomes: Fo...</td>\n",
       "      <td>AbstractSevere acute respiratory syndrome coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>10.1101/2021.05.11.443555</td>\n",
       "      <td>Mechanism of molnupiravir-induced SARS-CoV-2 m...</td>\n",
       "      <td>Molnupiravir is an orally available antiviral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>941</td>\n",
       "      <td>10.3390/ijms20020449</td>\n",
       "      <td>Bactericidal and Cytotoxic Properties of Silve...</td>\n",
       "      <td>Silver nanoparticles (AgNPs) can be synthesize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1141</td>\n",
       "      <td>10.3390/ijms20040865</td>\n",
       "      <td>Silver Nanoparticles: Synthesis and Applicatio...</td>\n",
       "      <td>Over the past few decades, metal nanoparticles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                        doi  \\\n",
       "0   128  10.1101/2021.05.10.443415   \n",
       "1   163  10.1101/2021.05.07.443114   \n",
       "2   200  10.1101/2021.05.11.443555   \n",
       "3   941       10.3390/ijms20020449   \n",
       "4  1141       10.3390/ijms20040865   \n",
       "\n",
       "                                               title  \\\n",
       "0  Improved protein contact prediction using dime...   \n",
       "1  Following the Trail of One Million Genomes: Fo...   \n",
       "2  Mechanism of molnupiravir-induced SARS-CoV-2 m...   \n",
       "3  Bactericidal and Cytotoxic Properties of Silve...   \n",
       "4  Silver Nanoparticles: Synthesis and Applicatio...   \n",
       "\n",
       "                                            abstract  \n",
       "0  AbstractDeep residual learning has shown great...  \n",
       "1  AbstractSevere acute respiratory syndrome coro...  \n",
       "2  Molnupiravir is an orally available antiviral ...  \n",
       "3  Silver nanoparticles (AgNPs) can be synthesize...  \n",
       "4  Over the past few decades, metal nanoparticles...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "print(f\"Metadata loaded: {len(metadata_df)} entries\")\n",
    "\n",
    "# Create train/test split (90/10 split)\n",
    "all_node_ids = [str(node_id) for node_id in metadata_df['id'].values]\n",
    "train_nodes, test_nodes = create_node_based_split(all_node_ids, test_ratio=0.1, seed=42)\n",
    "\n",
    "print(f\"\\nTrain nodes: {len(train_nodes)} ({len(train_nodes)/len(all_node_ids)*100:.1f}%)\")\n",
    "print(f\"Test nodes: {len(test_nodes)} ({len(test_nodes)/len(all_node_ids)*100:.1f}%)\")\n",
    "\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7d61dc-1313-49e1-9f62-55eb964d99bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading edgelist from /home/vikramr2/oc_mini/network/oc_mini_edgelist.csv...\n",
      "  Full graph: 111873 edges\n",
      "\n",
      "Filtering to induced subgraph of 12998 training nodes...\n",
      "  Induced subgraph: 91586 edges\n",
      "  Removed 20287 edges involving test nodes\n",
      "\n",
      "Node mapping:\n",
      "  Total nodes: 14442\n",
      "  Train nodes: 12998\n",
      "  Test nodes: 1444\n",
      "\n",
      "Final edge_index shape: torch.Size([2, 183172])\n",
      "  Directed edges: 183172\n",
      "\n",
      "✓ Verification: 0 edges involve test nodes (should be 0)\n",
      "\n",
      "Induced subgraph created:\n",
      "  Nodes in mapping: 14442\n",
      "  Edges: 183172\n",
      "\n",
      "======================================================================\n",
      "GRAPH STATISTICS\n",
      "======================================================================\n",
      "\n",
      "Training nodes (12998 nodes):\n",
      "  Mean degree: 14.09\n",
      "  Median degree: 10\n",
      "  Max degree: 1413\n",
      "  Isolated nodes: 79\n",
      "\n",
      "Test nodes (1444 nodes):\n",
      "  Mean degree: 0.00\n",
      "  Median degree: 0\n",
      "  Max degree: 0\n",
      "  Isolated nodes: 1444 (should be ALL)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create induced subgraph - KEY STEP FOR BASELINE\n",
    "# This graph will ONLY contain edges between training nodes\n",
    "# Test nodes will have NO edges (degree = 0)\n",
    "\n",
    "edge_index, node_to_idx, idx_to_node = create_induced_subgraph(\n",
    "    edgelist_path,\n",
    "    train_nodes,\n",
    "    metadata_df\n",
    ")\n",
    "\n",
    "print(f\"\\nInduced subgraph created:\")\n",
    "print(f\"  Nodes in mapping: {len(node_to_idx)}\")\n",
    "print(f\"  Edges: {edge_index.shape[1]}\")\n",
    "\n",
    "# Analyze statistics\n",
    "analyze_graph_statistics(edge_index, train_nodes, node_to_idx, metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90zaec92km",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Transformer weights frozen\n",
      "✓ Created 2-layer GCN model\n",
      "  Total GNN parameters: 1,181,184\n",
      "\n",
      "Model Summary:\n",
      "  Transformer: allenai/scibert_scivocab_uncased\n",
      "  Total parameters: 111,102,720\n",
      "  Trainable (GNN only): 1,184,256\n",
      "  Frozen (Transformer): 109,918,464\n"
     ]
    }
   ],
   "source": [
    "# Initialize TransformerGNN model with SciBERT\n",
    "# Key: Transformer is FROZEN, only GNN layers are trainable\n",
    "\n",
    "model_name = 'allenai/scibert_scivocab_uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = TransformerGNN(\n",
    "    model_name=model_name,\n",
    "    gnn_type='gcn',           # Use GCN layers\n",
    "    hidden_dim=768,           # Match SciBERT output\n",
    "    num_gnn_layers=2,         # 2 GNN layers\n",
    "    dropout=0.1,\n",
    "    pooling='cls',\n",
    "    freeze_transformer=True   # IMPORTANT: Freeze transformer!\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(f\"  Transformer: {model_name}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Trainable (GNN only): {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"  Frozen (Transformer): {sum(p.numel() for p in model.parameters() if not p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8x5l0g7une",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BASELINE DEMONSTRATION: GNN Degradation for Test Nodes\n",
      "======================================================================\n",
      "\n",
      "Test Node 1499677:\n",
      "  Cosine similarity: 0.593490 (1.0 = identical)\n",
      "  L2 difference: 0.90167600 (0.0 = identical)\n",
      "  ! Embeddings differ (unexpected)\n"
     ]
    }
   ],
   "source": [
    "# BASELINE DEMONSTRATION\n",
    "# Compare transformer-only vs GNN embeddings for test nodes\n",
    "# NOTE: get_node_texts() concatenates title + abstract for each node\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BASELINE DEMONSTRATION: GNN Degradation for Test Nodes\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sample a few test nodes\n",
    "import random\n",
    "sample_test_nodes = random.sample(test_nodes, min(5, len(test_nodes)))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for node_id in sample_test_nodes:\n",
    "        # 1. Get transformer-only embedding\n",
    "        # get_node_texts concatenates title + abstract\n",
    "        text = get_node_texts([node_id], metadata_df)[0]\n",
    "        inputs = tokenizer(\n",
    "            [text],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        transformer_emb = model.encode_text(inputs['input_ids'], inputs['attention_mask'])\n",
    "        transformer_emb = transformer_emb.cpu().numpy()[0]\n",
    "        \n",
    "        # 2. Get GNN embedding (full pipeline)\n",
    "        # First get all transformer embeddings (title + abstract for each)\n",
    "        all_node_ids = sorted(node_to_idx.keys(), key=lambda x: node_to_idx[x])\n",
    "        all_texts = get_node_texts(all_node_ids, metadata_df)\n",
    "        \n",
    "        # Encode all texts in batches\n",
    "        all_embs = []\n",
    "        batch_size = 32\n",
    "        for i in range(0, len(all_texts), batch_size):\n",
    "            batch_texts = all_texts[i:i+batch_size]\n",
    "            batch_inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            batch_embs = model.encode_text(batch_inputs['input_ids'], batch_inputs['attention_mask'])\n",
    "            all_embs.append(batch_embs)\n",
    "        \n",
    "        x = torch.cat(all_embs, dim=0)\n",
    "        \n",
    "        # Apply GNN\n",
    "        gnn_embs = model(x, edge_index.to(device))\n",
    "        \n",
    "        # Get embedding for this test node\n",
    "        node_idx = node_to_idx[node_id]\n",
    "        gnn_emb = gnn_embs[node_idx].cpu().numpy()\n",
    "        \n",
    "        # 3. Compare\n",
    "        cosine_sim = (transformer_emb * gnn_emb).sum()\n",
    "        l2_diff = np.sqrt(((transformer_emb - gnn_emb) ** 2).sum())\n",
    "        \n",
    "        print(f\"\\nTest Node {node_id}:\")\n",
    "        print(f\"  Cosine similarity: {cosine_sim:.6f} (1.0 = identical)\")\n",
    "        print(f\"  L2 difference: {l2_diff:.8f} (0.0 = identical)\")\n",
    "        \n",
    "        if cosine_sim > 0.999:\n",
    "            print(f\"  ✓ GNN = Transformer (as expected for nodes with no edges)\")\n",
    "        else:\n",
    "            print(f\"  ! Embeddings differ (unexpected)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"Test nodes have NO edges in the induced subgraph,\")\n",
    "print(\"so GNN provides NO benefit - it's just the transformer!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d065da-beae-4b77-99cc-d4bd9b339280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
