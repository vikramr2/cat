{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26022fd3",
   "metadata": {},
   "source": [
    "# Disjoint Clustering Fine-Tuning\n",
    "\n",
    "**Model: MedCPT**\n",
    "\n",
    "**Method: D-CAT (Disjoint Cluster)**\n",
    "\n",
    "**Data: OC-Mini**\n",
    "\n",
    "**Tuner: [Your Name]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND DIRECTORY INITIALIZATION\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.nn import TripletMarginLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_DIR = Path.cwd().parent.parent\n",
    "DATA_DIR = BASE_DIR / \"oc_mini\"\n",
    "\n",
    "# Add dcat module to path\n",
    "sys.path.insert(0, str(BASE_DIR / \"dcat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59d2a1",
   "metadata": {},
   "source": [
    "## Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d1bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(texts, model, tokenizer, device):\n",
    "    \"\"\"Compute embeddings for a list of texts.\"\"\"\n",
    "    if not texts:\n",
    "        return np.array([])\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    return embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLUSTER LOADING\n",
    "\n",
    "cluster_path = DATA_DIR / \"clustering\" / \"disjoint\" / \"oc_mini_clusters_0.001.csv\"\n",
    "metadata_path = DATA_DIR / \"metadata\" / \"oc_mini_node_metadata.csv\"\n",
    "\n",
    "cluster_df = pd.read_csv(cluster_path)\n",
    "\n",
    "# Sanity Check\n",
    "print(f\"Loaded cluster data: {cluster_df.shape[0]} nodes\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(cluster_df.head(10))\n",
    "\n",
    "print(f\"\\nCluster statistics:\")\n",
    "print(f\"  - Total unique nodes: {cluster_df['node'].nunique()}\")\n",
    "print(f\"  - Total unique clusters: {cluster_df['cluster'].nunique()}\")\n",
    "print(f\"\\nCluster size distribution:\")\n",
    "cluster_sizes = cluster_df['cluster'].value_counts()\n",
    "print(f\"  - Mean cluster size: {cluster_sizes.mean():.2f}\")\n",
    "print(f\"  - Median cluster size: {cluster_sizes.median():.0f}\")\n",
    "print(f\"  - Largest cluster: {cluster_sizes.max()} nodes\")\n",
    "print(f\"  - Smallest cluster: {cluster_sizes.min()} nodes\")\n",
    "\n",
    "print(f\"\\nCluster assignments loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MedCPT model and tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_name = \"ncbi/MedCPT-Article-Encoder\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "print(f\"MedCPT model loaded: {model_name}\")\n",
    "\n",
    "# Embed a sample sentence\n",
    "sample_sentence = \"The relationship between quantum mechanics and general relativity remains one of the most important unsolved problems in theoretical physics.\"\n",
    "\n",
    "embedding = compute_embeddings([sample_sentence], model, tokenizer, device)\n",
    "\n",
    "print(f\"\\nSample sentence: {sample_sentence}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"Embedding (first 10 dimensions): {embedding[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eb581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa802b9a",
   "metadata": {},
   "source": [
    "## Baseline Evaluation\n",
    "\n",
    "MedCPT is fine-tuned for medical literature. How well does it perform on downstream network-content tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATE ORIGINAL MEDCPT EMBEDDINGS (BEFORE FINE-TUNING)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUATING ORIGINAL MEDCPT ON LINK PREDICTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Import evaluation functions\n",
    "sys.path.append(str(BASE_DIR / \"utils\" / \"evaluation\"))\n",
    "from link_prediction import (\n",
    "    evaluate_network_link_prediction,\n",
    "    plot_link_prediction_results,\n",
    "    get_node_degree,\n",
    "    load_network_edges\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ddbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: COMPUTE EMBEDDINGS FOR ALL NODES\n",
    "# ============================================================================\n",
    "\n",
    "def compute_all_node_embeddings(model, tokenizer, metadata_df, device, batch_size=32):\n",
    "    \"\"\"Compute embeddings for all nodes in metadata\"\"\"\n",
    "    embeddings_dict = {}\n",
    "    \n",
    "    # Get all node IDs from metadata\n",
    "    node_ids = metadata_df['id'].astype(str).values\n",
    "    texts = []\n",
    "    valid_ids = []\n",
    "    \n",
    "    print(f\"Preparing texts for {len(node_ids)} nodes...\")\n",
    "    for node_id in tqdm(node_ids, desc=\"Preparing\"):\n",
    "        row = metadata_df[metadata_df['id'] == int(node_id)].iloc[0]\n",
    "        title = str(row['title']) if pd.notna(row['title']) else \"\"\n",
    "        abstract = str(row['abstract']) if pd.notna(row['abstract']) else \"\"\n",
    "        text = f\"{title} {abstract}\".strip()\n",
    "        \n",
    "        if text:  # Only add if we have text\n",
    "            texts.append(text)\n",
    "            valid_ids.append(node_id)\n",
    "    \n",
    "    print(f\"Computing embeddings for {len(texts)} nodes...\")\n",
    "    \n",
    "    # Compute embeddings in batches\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Computing embeddings\"):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_ids = valid_ids[i:i+batch_size]\n",
    "            \n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            # Use CLS token\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            embeddings = embeddings.cpu().numpy()\n",
    "            \n",
    "            for node_id, emb in zip(batch_ids, embeddings):\n",
    "                embeddings_dict[node_id] = emb\n",
    "    \n",
    "    return embeddings_dict\n",
    "\n",
    "# Compute embeddings using the ORIGINAL MedCPT model\n",
    "print(\"\\nComputing embeddings with original MedCPT...\")\n",
    "original_embeddings = compute_all_node_embeddings(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    metadata_df,\n",
    "    device,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Computed embeddings for {len(original_embeddings)} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: CREATE TEST SET (CLUSTER-BASED SPLIT)\n",
    "# ============================================================================\n",
    "\n",
    "# Import split utilities\n",
    "from split_utils import create_cluster_based_split\n",
    "\n",
    "# Create cluster-based train/test split (NO DATA LEAKAGE!)\n",
    "train_cluster_ids, test_cluster_ids, train_node_ids, test_node_ids = \\\n",
    "    create_cluster_based_split(cluster_df, test_ratio=0.1, seed=42)\n",
    "\n",
    "print(f\"\\n✓ Test set: {len(test_node_ids)} nodes from {len(test_cluster_ids)} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c93d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: RUN BASELINE LINK PREDICTION EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "edgelist_path = DATA_DIR / \"network\" / \"oc_mini_edgelist.csv\"\n",
    "\n",
    "# Run evaluation on baseline model\n",
    "baseline_results = evaluate_network_link_prediction(\n",
    "    edgelist_path=str(edgelist_path),\n",
    "    embeddings_dict=original_embeddings,\n",
    "    test_nodes=test_node_ids,  # Only test on held-out nodes!\n",
    "    k_values=[5, 10, 20, 50, 100],\n",
    "    compute_auc=True,\n",
    "    num_negative_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f303a",
   "metadata": {},
   "source": [
    "## D-CAT Fine-Tuning\n",
    "\n",
    "### Part 1: Disjoint Cluster Dataset\n",
    "\n",
    "Create a dataset that respects cluster boundaries for train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 1: DISJOINT CLUSTER TRIPLET DATASET\n",
    "# ============================================================================\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "class DisjointClusterTripletDataset(Dataset):\n",
    "    \"\"\"Dataset for disjoint cluster triplet learning\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cluster_df: pd.DataFrame,\n",
    "        metadata_df: pd.DataFrame,\n",
    "        tokenizer,\n",
    "        max_length: int = 512,\n",
    "        samples_per_cluster: int = 5,\n",
    "        train_clusters: List[int] = None\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.metadata_df = metadata_df.set_index('id')\n",
    "        \n",
    "        # Filter to train clusters if specified\n",
    "        if train_clusters is not None:\n",
    "            self.cluster_df = cluster_df[cluster_df['cluster'].isin(train_clusters)]\n",
    "        else:\n",
    "            self.cluster_df = cluster_df\n",
    "        \n",
    "        # Build cluster mappings\n",
    "        self.cluster_to_nodes = self._build_cluster_mapping()\n",
    "        \n",
    "        # Filter out single-node clusters\n",
    "        self.cluster_to_nodes = {\n",
    "            cid: nodes for cid, nodes in self.cluster_to_nodes.items() \n",
    "            if len(nodes) >= 2\n",
    "        }\n",
    "        \n",
    "        self.cluster_ids = list(self.cluster_to_nodes.keys())\n",
    "        \n",
    "        # Generate triplets\n",
    "        print(f\"Generating triplets from {len(self.cluster_ids)} clusters...\")\n",
    "        self.triplets = self._generate_triplets(samples_per_cluster)\n",
    "        print(f\"Generated {len(self.triplets)} triplets\")\n",
    "\n",
    "    def _build_cluster_mapping(self) -> Dict[int, List[str]]:\n",
    "        \"\"\"Build mapping from cluster ID to list of node IDs\"\"\"\n",
    "        cluster_to_nodes = {}\n",
    "        for cluster_id in self.cluster_df['cluster'].unique():\n",
    "            nodes = self.cluster_df[self.cluster_df['cluster'] == cluster_id]['node'].astype(str).tolist()\n",
    "            cluster_to_nodes[cluster_id] = nodes\n",
    "        return cluster_to_nodes\n",
    "\n",
    "    def _get_text(self, node_id: str) -> str:\n",
    "        \"\"\"Get combined title + abstract for a node\"\"\"\n",
    "        try:\n",
    "            row = self.metadata_df.loc[int(node_id)]\n",
    "            title = str(row['title']) if pd.notna(row['title']) else \"\"\n",
    "            abstract = str(row['abstract']) if pd.notna(row['abstract']) else \"\"\n",
    "            return f\"{title} {abstract}\".strip()\n",
    "        except (KeyError, ValueError):\n",
    "            return f\"Document {node_id}\"\n",
    "\n",
    "    def _generate_triplets(self, samples_per_cluster: int) -> List[Tuple[str, str, str]]:\n",
    "        \"\"\"Generate (anchor, positive, negative) triplets\"\"\"\n",
    "        triplets = []\n",
    "        \n",
    "        for cluster_id in tqdm(self.cluster_ids, desc=\"Mining triplets\"):\n",
    "            cluster_nodes = self.cluster_to_nodes[cluster_id]\n",
    "            \n",
    "            for _ in range(samples_per_cluster):\n",
    "                # Sample anchor and positive from same cluster\n",
    "                anchor_node, positive_node = np.random.choice(\n",
    "                    cluster_nodes, size=2, replace=False\n",
    "                )\n",
    "                \n",
    "                # Sample negative from different cluster\n",
    "                negative_cluster = np.random.choice(\n",
    "                    [c for c in self.cluster_ids if c != cluster_id]\n",
    "                )\n",
    "                negative_node = np.random.choice(\n",
    "                    self.cluster_to_nodes[negative_cluster]\n",
    "                )\n",
    "                \n",
    "                # Get texts\n",
    "                anchor_text = self._get_text(anchor_node)\n",
    "                positive_text = self._get_text(positive_node)\n",
    "                negative_text = self._get_text(negative_node)\n",
    "                \n",
    "                triplets.append((anchor_text, positive_text, negative_text))\n",
    "        \n",
    "        return triplets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor, positive, negative = self.triplets[idx]\n",
    "\n",
    "        # Tokenize all three\n",
    "        anchor_encoded = self.tokenizer(\n",
    "            anchor,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        positive_encoded = self.tokenizer(\n",
    "            positive,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        negative_encoded = self.tokenizer(\n",
    "            negative,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'anchor_input_ids': anchor_encoded['input_ids'].squeeze(0),\n",
    "            'anchor_attention_mask': anchor_encoded['attention_mask'].squeeze(0),\n",
    "            'positive_input_ids': positive_encoded['input_ids'].squeeze(0),\n",
    "            'positive_attention_mask': positive_encoded['attention_mask'].squeeze(0),\n",
    "            'negative_input_ids': negative_encoded['input_ids'].squeeze(0),\n",
    "            'negative_attention_mask': negative_encoded['attention_mask'].squeeze(0),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f1980",
   "metadata": {},
   "source": [
    "### Part 2: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 2: TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    \"\"\"Mean pooling with attention mask\"\"\"\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "def encode_batch(model, input_ids, attention_mask, pooling='cls'):\n",
    "    \"\"\"Encode a batch of text to embeddings\"\"\"\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    if pooling == 'mean':\n",
    "        embeddings = mean_pooling(outputs, attention_mask)\n",
    "    else:  # cls\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    # Normalize\n",
    "    embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, device, margin=1.0, pooling='cls'):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    triplet_loss_fn = TripletMarginLoss(margin=margin)\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        # Move to device\n",
    "        anchor_ids = batch['anchor_input_ids'].to(device)\n",
    "        anchor_mask = batch['anchor_attention_mask'].to(device)\n",
    "        pos_ids = batch['positive_input_ids'].to(device)\n",
    "        pos_mask = batch['positive_attention_mask'].to(device)\n",
    "        neg_ids = batch['negative_input_ids'].to(device)\n",
    "        neg_mask = batch['negative_attention_mask'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        anchor_emb = encode_batch(model, anchor_ids, anchor_mask, pooling)\n",
    "        pos_emb = encode_batch(model, pos_ids, pos_mask, pooling)\n",
    "        neg_emb = encode_batch(model, neg_ids, neg_mask, pooling)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = triplet_loss_fn(anchor_emb, pos_emb, neg_emb)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, device, margin=1.0, pooling='cls'):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    triplet_loss_fn = TripletMarginLoss(margin=margin)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            anchor_ids = batch['anchor_input_ids'].to(device)\n",
    "            anchor_mask = batch['anchor_attention_mask'].to(device)\n",
    "            pos_ids = batch['positive_input_ids'].to(device)\n",
    "            pos_mask = batch['positive_attention_mask'].to(device)\n",
    "            neg_ids = batch['negative_input_ids'].to(device)\n",
    "            neg_mask = batch['negative_attention_mask'].to(device)\n",
    "\n",
    "            anchor_emb = encode_batch(model, anchor_ids, anchor_mask, pooling)\n",
    "            pos_emb = encode_batch(model, pos_ids, pos_mask, pooling)\n",
    "            neg_emb = encode_batch(model, neg_ids, neg_mask, pooling)\n",
    "\n",
    "            loss = triplet_loss_fn(anchor_emb, pos_emb, neg_emb)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09144757",
   "metadata": {},
   "source": [
    "### Part 3: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae429a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PART 3: MAIN TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "def train_disjoint_triplet_loss(\n",
    "    cluster_df,\n",
    "    metadata_df,\n",
    "    train_cluster_ids,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    "    lr=2e-5,\n",
    "    margin=1.0,\n",
    "    samples_per_cluster=5,\n",
    "    pooling='cls',\n",
    "    train_split=0.9\n",
    "):\n",
    "    \"\"\"\n",
    "    Main training function for disjoint clustering\n",
    "\n",
    "    Args:\n",
    "        cluster_df: DataFrame with node and cluster columns\n",
    "        metadata_df: DataFrame with id, title, abstract\n",
    "        train_cluster_ids: List of cluster IDs for training (NO TEST LEAKAGE!)\n",
    "        model: Pretrained transformer model\n",
    "        tokenizer: Corresponding tokenizer\n",
    "        device: torch device\n",
    "        batch_size: Training batch size\n",
    "        epochs: Number of epochs\n",
    "        lr: Learning rate\n",
    "        margin: Triplet loss margin\n",
    "        samples_per_cluster: Triplets to generate per cluster\n",
    "        pooling: 'cls' or 'mean'\n",
    "        train_split: Train/validation split ratio\n",
    "\n",
    "    Returns:\n",
    "        Trained model and history\n",
    "    \"\"\"\n",
    "    # Create dataset with ONLY train clusters\n",
    "    print(\"Creating dataset from training clusters...\")\n",
    "    dataset = DisjointClusterTripletDataset(\n",
    "        cluster_df=cluster_df,\n",
    "        metadata_df=metadata_df,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=512,\n",
    "        samples_per_cluster=samples_per_cluster,\n",
    "        train_clusters=train_cluster_ids  # CRITICAL: Only train clusters!\n",
    "    )\n",
    "\n",
    "    # Split train/val\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size]\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    print(f\"Train: {len(train_dataset)} triplets, Val: {len(val_dataset)} triplets\")\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        print('='*60)\n",
    "\n",
    "        train_loss = train_epoch(\n",
    "            model, train_loader, optimizer, device, margin=margin, pooling=pooling\n",
    "        )\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "\n",
    "        val_loss = evaluate(model, val_loader, device, margin=margin, pooling=pooling)\n",
    "        print(f\"Val loss: {val_loss:.4f}\")\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            print(f\"✓ New best validation loss!\")\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training complete! Best val loss: {best_val_loss:.4f}\")\n",
    "    print('='*60)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d22d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN TRAINING (ONLY ON TRAIN CLUSTERS!)\n",
    "# ============================================================================\n",
    "\n",
    "# Train the model - CRITICAL: Only use train_cluster_ids!\n",
    "finetuned_model, history = train_disjoint_triplet_loss(\n",
    "    cluster_df=cluster_df,\n",
    "    metadata_df=metadata_df,\n",
    "    train_cluster_ids=train_cluster_ids,  # Only train clusters!\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    batch_size=16,\n",
    "    epochs=3,\n",
    "    lr=2e-5,\n",
    "    margin=1.0,\n",
    "    samples_per_cluster=5,\n",
    "    pooling='cls',\n",
    "    train_split=0.9\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], marker='o', label='Train Loss', linewidth=2)\n",
    "plt.plot(history['val_loss'], marker='s', label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Disjoint Cluster Triplet Loss Training', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb1d76c",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "How well does D-CAT perform on downstream tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de145e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings with fine-tuned model\n",
    "print(\"\\nComputing embeddings with fine-tuned model...\")\n",
    "finetuned_embeddings = compute_all_node_embeddings(\n",
    "    finetuned_model,\n",
    "    tokenizer,\n",
    "    metadata_df,\n",
    "    device,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"✓ Computed embeddings for {len(finetuned_embeddings)} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATE FINE-TUNED MODEL ON TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "# Evaluate link prediction on TEST set only\n",
    "finetuned_results = evaluate_network_link_prediction(\n",
    "    edgelist_path=str(edgelist_path),\n",
    "    embeddings_dict=finetuned_embeddings,\n",
    "    test_nodes=test_node_ids,  # Same test set as baseline!\n",
    "    k_values=[5, 10, 20, 50, 100],\n",
    "    compute_auc=True,\n",
    "    num_negative_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPARE BASELINE VS FINE-TUNED\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE COMPARISON: BASELINE VS FINE-TUNED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = {\n",
    "    'K': [],\n",
    "    'Baseline Precision@K': [],\n",
    "    'Fine-tuned Precision@K': [],\n",
    "    'Improvement': []\n",
    "}\n",
    "\n",
    "for k in [5, 10, 20, 50, 100]:\n",
    "    bl_prec = baseline_results['topk']['summary'][k]['precision@k']\n",
    "    ft_prec = finetuned_results['topk']['summary'][k]['precision@k']\n",
    "    improvement = ((ft_prec - bl_prec) / bl_prec) * 100 if bl_prec != 0 else 0\n",
    "    \n",
    "    comparison_data['K'].append(k)\n",
    "    comparison_data['Baseline Precision@K'].append(f\"{bl_prec:.4f}\")\n",
    "    comparison_data['Fine-tuned Precision@K'].append(f\"{ft_prec:.4f}\")\n",
    "    comparison_data['Improvement'].append(f\"{improvement:+.2f}%\")\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# AUC comparison\n",
    "if 'auc' in baseline_results and 'auc' in finetuned_results:\n",
    "    bl_auc = baseline_results['auc']['auc_roc']\n",
    "    ft_auc = finetuned_results['auc']['auc_roc']\n",
    "    auc_improvement = ((ft_auc - bl_auc) / bl_auc) * 100\n",
    "    \n",
    "    print(f\"\\nAUC-ROC:\")\n",
    "    print(f\"  Baseline: {bl_auc:.4f}\")\n",
    "    print(f\"  Fine-tuned: {ft_auc:.4f}\")\n",
    "    print(f\"  Improvement: {auc_improvement:+.2f}%\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88594af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Precision@K comparison\n",
    "k_values = [5, 10, 20, 50, 100]\n",
    "bl_precs = [baseline_results['topk']['summary'][k]['precision@k'] for k in k_values]\n",
    "ft_precs = [finetuned_results['topk']['summary'][k]['precision@k'] for k in k_values]\n",
    "\n",
    "ax1.plot(k_values, bl_precs, marker='o', linewidth=2, label='Baseline', color='#e74c3c')\n",
    "ax1.plot(k_values, ft_precs, marker='s', linewidth=2, label='Fine-tuned', color='#2ecc71')\n",
    "ax1.set_xlabel('K', fontsize=12)\n",
    "ax1.set_ylabel('Precision@K', fontsize=12)\n",
    "ax1.set_title('Link Prediction Performance', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Improvement bars\n",
    "improvements = [(ft - bl) for bl, ft in zip(bl_precs, ft_precs)]\n",
    "colors = ['#2ecc71' if imp > 0 else '#e74c3c' for imp in improvements]\n",
    "ax2.bar(range(len(k_values)), improvements, color=colors, alpha=0.7)\n",
    "ax2.set_xlabel('K', fontsize=12)\n",
    "ax2.set_ylabel('Δ Precision@K', fontsize=12)\n",
    "ax2.set_title('Performance Improvement', fontsize=13, fontweight='bold')\n",
    "ax2.set_xticks(range(len(k_values)))\n",
    "ax2.set_xticklabels(k_values)\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529f36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
